\chapter{Theoretische Grundlagen für die Modellierung}

In diesem Kapitel sollen die in der Arbeit verwendeten mathematischen Hilfsmittel vorgestellt werden und die wichtigsten Eigenschaften bewiesen werden. Dabei werden Grundlegende Kenntnisse im Bereich der Wahrscheinlichkeitstheorie vorausgesetzt und dass Begriffe wie Wahrscheinlichkeitsraum, Zufallsvariable, Dichte- und Verteilungsfunktion bekannt sind. Im Folgenden ist der Wahrscheinlichkeitsraum immer definiert durch $(\Omega,\mathfrak{A},\mathbb{P})$.
\\

Zunächst werden wir die Verteilungen vorstellen, die in dieser Arbeit verwendet werden, und die wichtigsten Eigenschaften ableiten.

\begin{defini}
Eine Zufallsvariable $X:\Omega\to \mathbb{R}$ heißt \textbf{exponentialverteilt zum Parameter $\lambda$} (kurz: $\sim exp(\lambda)$) wenn sie die folgende Dichtefunktion besitzt:
	\begin{eqnarray*}
		f(x)=
		\begin{cases}
			\lambda e^{-\lambda x} & \text{für } x\geq 0 \\ 	
			0 & \text{für } x<0 \\ 
		\end{cases}
	\end{eqnarray*}
\end{defini}

\begin{figure}[ht]
   \centering
      \subfloat[Dichtefunktion]{\includegraphics[width=0.39\textwidth]{./bilder/ExpDichteF}}\qquad
      \subfloat[Verteilungsfunktion]{\includegraphics[width=0.39\textwidth]{./bilder/ExpVerteilungF}}
   \caption[Dichte- und Verteilungsfunktion der Exponentialverteilung]{Dichte- und Verteilungsfunktion der Exponentialverteilung}
\end{figure}

Die Exponentialverteilung hat folgende Eigenschaften:

\begin{enumerate}[label=(\roman{*})]
	\item Die Verteilungsfunktion der Exponentialverteilung ist: 
	\begin{eqnarray*}
		F_{\lambda}(x) = \int_{-\infty}^{x} f_{\lambda}(t) dt =
		\begin{cases}
			1-e^{-\lambda x} & \text{für } x\geq 0 \\ 	
			0 & \text{für } x<0 \\ 
		\end{cases}
	\end{eqnarray*}
	\item Der Erwartungswert ist:
	\begin{eqnarray*}
			\mathbb{E}(X) = \int_0^{\infty}\lambda xe^{-\lambda x} dx 
										= \left[-\frac{e^{-\lambda x}(\lambda x +1)}{\lambda}\right]^{\infty}_0
										= \frac{1}{\lambda}
	\end{eqnarray*}
	\item Die Varianz ist: 
	\begin{eqnarray*}
		Var(X) = \int_{\infty}^{0} \left(x-\frac{1}{\lambda}\right)^2 \lambda e^{-\lambda x} dx = \frac{1}{\lambda^2}
	\end{eqnarray*}
	\item Die Exponentialverteilung ist gedächtnislos (auch Nichtalterungseigenschaft genannt), d.h.:
	\begin{eqnarray*}
		F(x|t) := \mathbb{P}(x+t\leq X , t<X) &=& \frac{\mathbb{P}(t<X<x+t)}{\mathbb{P}(t<X)} \\
					 &=& \frac{\mathbb{P}(X\leq x+t) - \mathbb{P}(t\leq X)}{1-\mathbb{P}(t\leq X)} \\
					 &=& \frac{1-e^{-\lambda (x+t)} - (1-e^{-\lambda t})}{1-(1-e^{-\lambda t})} \\
					 &=& \frac{-e^{-\lambda x -\lambda t} + e^{-\lambda t}}{e^{-\lambda t}} \\
					 &=& \frac{e^{-\lambda t}(1-e^{-\lambda x})}{e^{-\lambda t}} \\
					 &=& 1-e^{-\lambda x} = \mathbb{P}(x\leq X) = F(x)
	\end{eqnarray*}
\end{enumerate}

Es lässt sich sogar zeigen, dass die Exponentialverteilung die einzige stetige Verteilung\footnote{Im diskreten Fall ist dies die geometrische Verteilung.} mit Nichtalterungseigenschaft ist:

\begin{lemmas} \label{expLemma} Wenn die Überlebenswahrscheinlichkeit ($\overline{F}(x) := 1-F(x)$) einer nicht ausgearteten, nicht negativen Zufallsvariable X der folgenden Beziehung genügt:
  \begin{equation}
		\mathbb{P}(x+t\leq X) = \mathbb{P}(x\leq X)\mathbb{P}(t\leq X)	\label{eq:lemma1}
	\end{equation}
dann gilt $X\sim exp(\lambda)$ für ein $\lambda >0$.
\end{lemmas}

\textbf{Beweis:}
Mit der Definition $f(x) := \mathbb{P}(x<X)$ lässt sich \ref{eq:lemma1} zu folgender Gleichung umformen
	\begin{eqnarray*}
		f(x+t) = f(x)f(t) \text{, mit} f(0) = \mathbb{P}(0\leq X) = 1
	\end{eqnarray*}
die sich wie folgt umformen lässt:
	\begin{eqnarray*}
		ln(f(x+t)) = ln(f(x)) + ln(f(t))
	\end{eqnarray*}
Unter der Voraussetzung, das die Dichte $p_X(t) = -f(t+0), t\geq 0$ existiert, ergibt sich durch Differentiation nach t:
	\begin{eqnarray*}
		\frac{f^{'}(x+t)}{f(x+t)} = \frac{f^{'}(t)}{f(t)} 
	\end{eqnarray*}
Für $t=0$ folgt damit:
	\begin{eqnarray*}
		\frac{f^{'}(x)}{f(x)} = f^{'}(t)
	\end{eqnarray*}
Da $f(0) = 1$ der maximale Wert der Funktion f(x) ist, gilt $0\geq f^{'}(0) := -\lambda$ und damit erhalten wir die bekannte Differentialgleichung:
	\begin{alignat*}{2}
		&& f^{'}(x) &= -\lambda f(x) \\
		&\Rightarrow & f(x) &= e^{-\lambda x} \\
		&\Rightarrow & F(x) &= 1-f(x) = 1-e^{-\lambda x} \\
		&\Rightarrow & X &\sim exp(\lambda)
	\end{alignat*}
\qed

\begin{defini}
Eine diskrete Zufallsvariable $X:\Omega\to \mathbb{N}$ heißt \textbf{Poisson-verteilt zum Parameter $\lambda \in \mathbb{R}_{>0}$} (kurz $X\sim Poi(\lambda)$), wenn gilt:
\begin{eqnarray*}
	\mathbb{P}(X=k) = \frac{\lambda^k}{k!}e^{-\lambda}, k=0,1,2,...
\end{eqnarray*}
\end{defini}

Die Poisson-Verteilung hat folgende Eigenschaften:

\begin{enumerate}[label=(\roman{*})]
	\item Die Verteilungsfunktion der Poisson-Verteilung ist: 
	\begin{eqnarray*}
		F_{\lambda}(n) = \sum_{k=0}^{n} \mathbb{P}_{\lambda}(k) = e^{-\lambda} \sum_{k=0}^{n} \frac{\lambda^k}{k!}
	\end{eqnarray*}
	\item Der Erwartungswert ist:
	\begin{eqnarray*}
			\mathbb{E}(X) &=& \sum_{k=0}^{\infty} k\frac{\lambda^k}{k!} e^{-\lambda}  
										=  0 + \sum_{k=1}^{\infty} k\frac{\lambda^k}{k!} e^{-\lambda} \\
										&=& \lambda e^{-\lambda} \sum_{k=1}^{\infty} \frac{\lambda^{k-1}}{(k-1)!} \\
										&=& \lambda e^{-\lambda} \sum_{i=0}^{\infty} \frac{\lambda^i}{i!} 
										= \lambda e^{-\lambda} e^{\lambda} 
										= \lambda
	\end{eqnarray*}
	
	Der Parameter $\lambda$ der Poisson-Verteilung kann also, als die erwartete Ereignishäufigkeit pro Zeiteinheit interpretiert werden.
	
	\item Die Varianz ist: 
	\begin{eqnarray*}
		\mathbb{E}(X^2) &=& \sum_{k=0}^{\infty} k^2 \frac{\lambda^k}{k!} e^{-\lambda} \\
										&=& e^{-\lambda} \sum_{k=1}^{\infty} k \frac{\lambda^{k}}{(k-1)!} \\
										&=& e^{-\lambda} \sum_{k=2}^{\infty} \frac{\lambda^{k}}{(k-2)!} + e^{-\lambda} \sum_{k=1}^{\infty} \frac{\lambda^{k}}{(k-1)!} \\
										&=& \lambda^2 e^{-\lambda} \sum_{k=2}^{\infty} \frac{\lambda^{k-2}}{(k-2)!} + \lambda e^{-\lambda} \sum_{1}^{\infty} \frac{\lambda^{k-1}}{(k-1)!} \\
										&=& \lambda^2+\lambda \\ \\
						 Var(X) &=& \mathbb{E}(X^2) - \mathbb{E}(X)^2 = \lambda^2+\lambda - \lambda^2 = \lambda
	\end{eqnarray*}
	\item Seien $X_1$ und $X_2$ unabhängige poissonverteilte Zufallsvariablen mit $X_1\sim Poi(\lambda _1)$ und $X_2\sim Poi(\lambda _2)$, dann gilt für $X := X_1 + X_2 $:
		\begin{eqnarray*}
			\mathbb{P}(X=x) &=& \sum_{k=0}^{x} \mathbb{P}(X_1=k)\mathbb{P}(X_2=x-k) \\
											&=& e^{-\lambda_1}e^{-\lambda_2} \sum_{k=0}^{x} \frac{\lambda _{1} ^k}{k!} \frac{\lambda _{2} ^{x-k}}{(x-k)!} \\
											&=& \frac{e^{-(\lambda_1+\lambda_2)}}{x!} \sum_{k=0}^{x} \frac{x!}{k!(x-k)!}\lambda _{1}^k \lambda _{2}^{x-k} \\
											&=& e^{-(\lambda_1+\lambda_2)} \frac{(\lambda _{1} + \lambda _{2})^x}{x!} \\
				\Rightarrow  X &\sim & Poi(\lambda _1 + \lambda _2) 
		\end{eqnarray*}
		Das heißt die Summe von poissonverteilten Zufallsvariablen ist wieder poissonverteilt.
	\end{enumerate}

Die Poisson-Verteilung hat außerdem eine besondere Bedeutung, da sie unter den richtigen Voraussetzungen die Grenzverteilung der Binomialverteilung ist. Dieser Zusammenhang wird in folgendem Lemma verdeutlicht: \\

\begin{lemmas} Die Poisson-Verteilung ist die Grenzverteilung der Binomial-Verteilung $B_{n,p}(k)$, wenn für die Erfolgswahrscheinlichkeit $p$ gilt $p\rightarrow 0$ und für die Anzahl der Versuche $n$ gilt $n\rightarrow \infty$ und außerdem für das Produkt $\lambda := np$ gilt $\lambda \neq 0$ und $\lambda \neq \infty$. 
\end{lemmas}

\textbf{Beweis:}
Entsprechend der Nebenbedingung können wir $p$ durch $\frac{\lambda}{n}$ ersetzen und damit ist die Bedingung $p\rightarrow 0$ äquivalent zu $n\rightarrow \infty$ und wir müssen somit nur einen Grenzwert bestimmen. Wir zeigen, dass der Grenzwert $n\rightarrow \infty$ einer binomialverteilten Zufallsvariable an der Stelle k, gegen den Wert einer poissonverteilten Zufallsvariablen an der Stelle k geht. 
	\begin{eqnarray*}
		\lim_{n\rightarrow \infty} \mathbb{P}(X=k) &=& \lim_{n\rightarrow \infty} \frac{n!}{k!(n-k)!} \left(\frac{\lambda}{n}\right)^k \left(1-\frac{\lambda}{n}\right)^{n-k} \\
		&=& \lim_{n\rightarrow \infty} \frac{\lambda ^k}{k!} \frac{n(n-1)(n-2)...(n-k+1)}{n^k} \left( 1-\frac{\lambda}{n}\right)^{n} \left(1-\frac{\lambda}{n}\right)^{-k} \\
		&=& \frac{\lambda ^k}{k!} * 1 * e^{-\lambda} * 1 \\
		&=& \frac{\lambda ^k e^{-\lambda}}{k!}		
	\end{eqnarray*}
\qed
	
\begin{defini}
Ein \textbf{Stochastischer Prozess $X$} ist eine Familie von Zufallsvariablen $\{X_t\}$ mit $X_t:\Omega\to \mathfrak{A}, t\in T$. Für die Indexmenge T gilt in der Regel $T\in \{\mathbb{R}_{\geq 0}, \mathbb{N}_0\}$. Das heißt $X$ ist eine Abbildung
\begin{eqnarray*}
	X:\Omega \times T \to Z, \; (\omega, t) \mapsto X_t(\omega)
\end{eqnarray*}
sodass $X_t: \omega \mapsto X_t(\omega)$ für alle  $t \in T$ eine messbare Abbildung ist.
\end{defini}

\begin{enumerate}[label=(\roman{*})]
	\item Ein stochastische Prozess heißt \textbf{zeitdiskret} wenn $T$ abzählbar ist, z.B. $T = \mathbb{N}_0$. Ansonsten heißt er \textbf{zeitstetig}. 
	Analog heißt ein Prozess mit diskreten Zustandsraum $\mathfrak{A}$ \textbf{wertdisktret} oder auch \textbf{Punktprozess}. 
	\item Ein stochastische Prozess heißt \textbf{stationär}, wenn für alle $s>0$, sowie $t_1,t_2,...,t_k\in T$ und $x_1,x_2,...,x_k \in \mathfrak{A}$ gilt:
		\begin{eqnarray*}
			\mathbb{P}(X_{t_1+s}=x_1, X_{t_2+s}=x_2,..., X_{t_k+s}=x_k)=\mathbb{P}(X_{t_1}=x_1, X_{t_2}=x_2,..., X_{t_k}=x_k)				
		\end{eqnarray*}
		Das heißt, das zufällige Verhalten des Prozesses hängt nicht vom Zeitpunkt der Beobachtung ab.
	\item Ein stochastischer Prozess besitzt \textbf{Unabhängige Zuwächse}, wenn die Zufallsvariablen $X_{t_0},X_{t_1}-X_{t_0},...,,X_{t_n}-X_{t_{n-1}}$ für alle n=1,2,... und $0\leq t_0<t_1<...<t_n$ unabhängig sind.
\end{enumerate}

\begin{defini}
Sei $T_1, T_2, ... : \omega \rightarrow [0, \infty)$ eine Folge von unabhängig und identisch verteilten Zufallsvariablen, dann ist $N := \{N_t, t\geq 0\}$ mit
\begin{eqnarray*}
		N_t = \sum_{k=1}^{\infty} \mathbb{I}(S_k\leq t) \text{ und } S_n = T_1+...+T_n 
\end{eqnarray*}
ein stochastischer Prozess und wird als Zählprozess bezeichnet. 
\end{defini}

Prozesse dieser Art werden z.B. in der Zuverlässigkeitstheorie eingesetzt um die Ausfälle einer Komponente in einem bestimmten Zeitraum zu zählen. Deshalb werden die $T_n$ häufig als \textbf{Zwischenankunftszeiten} bezeichnet.

\begin{defini} \label{poiPro}
Ein Zählprozess $\{N_t, t\geq 0\}$ mit exponentialverteilten Zwischenankunftszeiten $T_n \sim exp(\lambda)$ heißt \textbf{homogener Poisson-Prozess mit der Intensität $\lambda$}.  
\end{defini}

In folgendem Theorem werden die wichtigsten Eigenschaften des Poisson deutlich:

\begin{theorem} Die folgenden Aussagen sind äquivalent\footnote{siehe: \url{http://www.mathematik.uni-ulm.de/stochastik/lehre/ss05/wt/skript/node15.html}}:
\begin{enumerate}[label=(\roman{*})]
	\item $\{N_t, t\geq 0\}$ ist ein Poisson-Prozess mit der Intensität $\lambda$
	\item Die Zufallsvariablen $N_t$ sind poissonverteilt zum Parameter $\lambda t$ für alle $t\geq 0$. Unter der Bedingung $\{N_t = n\}$, hat für beliebige $n=1,2,...$ der Zufallsvektor $(S_1, S_2,...,S_n)$, die gleiche Verteilung wie die Ordnungsstatistik von n unabhängigen, in $[0,t]$ gleichverteilten Zufallsvariablen.
	\item Der stochastische Prozess $\{N_t\}$ hat unabhängige Zuwächse und es gilt $\mathbb{E}(N_1) = \lambda$. Unter der Bedingung $\{N_t = n\}$, hat für beliebige $n=1,2,...$ der Zufallsvektor $(S_1, S_2,...,S_n)$, die gleiche Verteilung wie die Ordnungsstatistik von n unabhängigen, in $[0,t]$ gleichverteilten Zufallsvariablen.
	\item Der stochastische Prozess $\{N_t\}$ hat unabhängige Zuwächse und ist stationär und es gilt für $h \downarrow 0$:
	\begin{eqnarray*}
		\mathbb{P}(N_h =0) &=& 1-\lambda h + o(h) \text{, und} \\
		\mathbb{P}(N_h =1) &=& \lambda h + o(h)\
	\end{eqnarray*}
	\item Der stochastische Prozess $\{N_t\}$ hat unabhängige Zuwächse und ist stationär. Außerdem gilt für jedes $t\geq 0$ das $N_t \sim Poi(\lambda t)$.
\end{enumerate}
\end{theorem}

\textbf{Beweis:} 
\begin{itemize}
\item $(i) \Rightarrow (ii)$:
	Aus $(i)$ folgt, dass $S_n=\sum_{i=1}^n T_i$ eine Summe von $n$ unabhängigen und zum Parameter $\lambda$ exponentialverteilten Zufallsvariablen ist, 	d.h., $S_n \sim Erl(n,\lambda)$, wobei $Erl(n,\lambda)$ die Erlang-Verteilung mit den Parametern $n$ und $\lambda$ bezeichnet. Hieraus folgt $\mathbb{P}(N_t = 0) = \mathbb{P}(S_1 > t) = e^{-\lambda t}$ und damit folgt:

\begin{eqnarray*}	 
\mathbb{P}(N_t = n) &=&\mathbb{P}(N_t \geq n) - \mathbb{P}(N_t \geq n+1) \\	 
				&=&\mathbb{P}(S_n \leq t)- \mathbb{P}(S_{n+1} \leq t) \\
				&=&\int_0^t \frac{\lambda^n v^{n-1}}{(n-1)!} e^{-\lambda v} \mathrm{d}v - \int_0^t \frac{\lambda^{n+1}v^n}{n!} e^{-\lambda v} \mathrm{d}v	 \\
				&=&\int_0^t \frac{\mathrm{d}}{\mathrm{d}v} \left(\frac{(\lambda v)^n}{n!} e^{-\lambda v}\right) \mathrm{d}v \\
				&=&\frac{(\lambda t)^n}{n!} e^{-\lambda t}
\end{eqnarray*}
Dies gilt für jedes $n\geq 1$, und damit folgt, dass $N_t \sim Poi(\lambda t)$, womit der erste.

\item $(ii) \Rightarrow (iii)$: TODO
\end{itemize}
\qed

Die folgende sehr nützliche Eigenschaft ist bereits von der Poisson-Verteilung bekannt:

\begin{lemmas}
Die Überlagerung von zwei unabhängigen Poisson-Prozessen $\{N_t^1, t\geq 0\}$ und $\{N_t^1, t\geq 0\}$  mit der Intensität $\lambda _1$ bzw. $\lambda _2$ ist wieder ein Poisson-Prozess mit Intensität $\lambda = \lambda _1+\lambda _2$.
\end{lemmas}
\textbf{Beweis:} 
Im vorangegangen Theorem hab wir gezeigt, dass für einen Poisson-Prozess $\{N_t, t\geq 0\}$ gilt $N_t \sim Poi(\lambda t)$. Da $\{N_t^1, t\geq 0\}$ und $\{N_t^1, t\geq 0\}$ unabhängig sind gilt für die Summe $N_t^1 + N_t^2 \sim Poi((\lambda _1 + \lambda _2)t)$. Damit ist die Überlagerung der beiden Poisson-Prozesse wieder ein Poisson-Prozess mit Intensität $\lambda = \lambda _1+\lambda _2$.
\qed \\

Als nächstes werden wir eine weitere wichtige Klasse an stochastischen Prozessen vorstellen, doch vorher müssen wir noch den Begriff der stochastischen Matrix einführen:

\begin{defini} Eine Matrix $P = (p_{i,j})$ heißt \textbf{stochastisch}, falls für alle $i, j \in I$ (Indexmenge) gilt  $p_{i,j} \in [0, 1]$ und $\sum_{j \in I} p_{i,j} = 1$.
\end{defini}

\begin{defini} 
Ein Stochastischer Prozess $\{X_t, t\geq 0\}$ besitzt die \textbf{Markoveigenschaft}, wenn für alle $i_0,i_1,...,i_{n+1} \in \mathfrak{A}$ gilt:
\begin{eqnarray*}
	\mathbb{P}(X_{t+1}=i_{t+1}|X_t=i_t,X_{t-1}=i_{t-1},...,X_0=i_0) = \mathbb{P}(X_{t+1}=i_{t+1}|X_t=i_t)
\end{eqnarray*}
Ein solcher Prozess heißt im stetigen Fall \textbf{Markovscher Prozess} und \textbf{Markov-Kette} im diskreten Fall. Die \textbf{Startverteilung} der Markov-Kette ist definiert durch $v(i) = \mathbb{P}(X_0 = i)$ und die Wahrscheinlichkeiten $\mathbb{P}(X_{t+1}=i_{t+1}|X_t=i_t) =: p_{i_t , i_{t+1}}$ werden als \textbf{Übergangswahrscheinlichkeiten} bezeichnet.  Die Matrix $P = (p_{i,j})_{i, j \in \mathfrak{A}}$ die sich aus den Übergangswahrscheinlichkeiten ergibt, ist eine stochastische Matrix und heißt \textbf{Übergangsmatrix}.
\end{defini}

Der nächste Zustand einer Markov-Kette hängt also immer nur von dem aktuellen Zustand ab. D.h. die Kette wird durch die Übergangswahrscheinlichkeiten charakterisiert. \\

TODO:
\begin{itemize}
	\item Eigenschaften der Markov-Kette charakterisieren
  \item Pfade durch Potenzen der Übergangsmatrix
  \item Irreduzibilität
  \item Rekurrenz und Transienz
  \item Absorbierende Zustände
  \item Stationäre Verteilung
  \item Ergodizität
\end{itemize}

%Für eine Zufallsvariable $X:\Omega\to \mathbb{R}$ bezeichnen wir die Abbildung $F_X: \mathbb{R}\to [0,1]$, definiert durch
%\begin{eqnarray*}
%F_X\left(x\right):=\Pro\left(X \leq x\right)
%\end{eqnarray*}
%als \textbf{Verteilungsfunktion} von $X$. Wir schreiben $X\sim F_X$ um auszudrücken, dass $F_X$ die Verteilungsfunktion von $X$ ist. Weiterhin definieren wir mittels
%\begin{eqnarray*}
%\overline{F_X}\left(x\right):=1-F_X\left(x\right)
%\end{eqnarray*}
%die \textbf{Schwanzfunktion} $\overline{F_X}$ von $X$.
%
%Zudem definieren wir für eine Verteilungsfunktion $F$ die \textbf{verallgemeinerte inverse Verteilungsfunktion} $F^{-1}$ mittels
%\begin{equation}
%F^{-1}(x)=\inf\left\{t\in\mathbb{R}\mid F(t)\geq x\right\}\text{,}
%\label{defAllgmeineInverse}
%\end{equation}
%wobei wir $\inf \emptyset :=\infty$ setzen.
%
%\begin{lemma}
%Sei $F$ eine Verteilungsfunktion und sei die Zufallsvariable $U:\Omega\to [0,1]$ gleichförmig auf $[0,1]$ verteilt. Dann gilt
%\begin{equation*}
%F^{-1}(U)\sim F\text{.}
%\end{equation*}
%\label{lemmaInverse}
%\end{lemma}
%
%\proof
%Wir zeigen zunächst, dass für alle $x,y\in\mathbb{R}$ genau dann $F(x)\geq y$ erfüllt ist, wenn $x\geq F^{-1}(y)$ gilt.
%
%Falls $x,y$ derart sind, dass $F(x)\geq y$ erfüllt ist, so folgt direkt aus der Definition der verallgemeinerte inversen Verteilungsfunktion (\ref{defAllgmeineInverse}), dass $x\geq F^{-1}(y)$ gelten muss.
%
%Seien andererseits $x,y$ gegeben, so dass $x\geq F^{-1}(y)$ gilt. Sei weiter eine monoton fallende Folge $(x_n)_{n\in\mathbb{N}}$ mit $\lim\limits_{n\to\infty}x_n =x$ gegeben. Da $x\geq F^{-1}(y)$ gilt und $F$ als Verteilungsfunktion monoton wachsend ist, folgt $F(x_n)\geq y$ für alle $n\in\mathbb{N}$. Da $F$ als Verteilungsfunktion zudem rechtsstetig ist, folgt weiterhin
%\begin{equation*}
%F(x)=\lim_{n\to\infty}F(x_n)\geq y\text{.}
%\end{equation*}
%Damit gilt $F(x)\geq y$ genau dann, wenn $x\geq F^{-1}(y)$. 
%
%Mittels der Definition der verallgemeinerten inversen Verteilungsfunktion sehen wir, dass $F^{-1}$ eine monotone Funktion ist und somit auch messbar ist. Damit ist $F^{-1}(U)$ tatsächlich eine Zufallsvariable und es folgt aus obiger Äquivalenz
%\begin{equation*}
%\Pro(F^{-1}(U)\leq x) = \Pro(U \leq F(x)) = F(x)\text{,}
%\end{equation*}
%das heißt $F^{-1}(U)\sim F$ gilt.
%\qed
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\section{Die stochastische Dominanz}
%
%Wir wollen nun Konzepte finden, um Risiken zu vergleichen. Ohne Zweifel würden wir sagen, dass ein Risiko $X$ im Vergleich mit einem zweiten Risiko $Y$ größer ist, wenn die Wahrscheinlichkeit, dass ein Schaden des Risikos $Y$ mindestens die Höhe $x$ aufweist für alle $x$ stets mindestens so groß ist wie dieselbe Wahrscheinlichkeit für das Risiko $X$. Dies motiviert uns zu folgender Definition:
%
%\begin{defi}
%Für zwei nichtnegative Zufallsvariablen $X,Y$ sagen wir das Risiko $Y$ ist \textbf{größer} als das Risiko $X$ oder $Y$ \textbf{dominiert} $X$ \textbf{stochastisch}, falls 
%\begin{eqnarray*}
%\Pro\left(X>x\right)\leq\Pro\left(Y>x\right) 
%\end{eqnarray*}
%für alle $x\in \mathbb{R}$ gilt und schreiben dann $X\leq_{st}Y$.
%\end{defi}
%
%\begin{bemerkung}
%Somit gilt $X\leq_{st}Y$ genau dann, wenn $\overline{F_X}\left(x\right)\leq\overline{F_Y}\left(x\right)$ beziehungsweise $F_X\left(x\right)\geq F_Y\left(x\right)$ für alle $x\geq 0$ gilt. Wie man sofort sieht, ist obige Ordnung durch die Verteilungsfunktion der Zufallsvariablen bestimmt. Dies rechtfertigt das Nutzen dieser Ordnung auf der Menge der Verteilungen. Dementsprechend schreiben wir $F_X\preceq_{st}F_Y$ genau dann, wenn $X\leq_{st}Y$ für Zufallsvariablen $X\sim F_X$ und $Y\sim F_Y$ gilt und sagen, dass die Verteilung $F_Y$ die Verteilung $F_X$ stochastisch dominiert.
%
%Weiterhin bemerken wir, dass $\preceq_{st}$ eine Halbordnung auf der Menge der Verteilungsfunktionen ist, denn wie man leicht sieht ist $\preceq_{st}$ reflexiv, transitiv und antisymmetrisch.
%\end{bemerkung}
%
%Mittels folgender Eigenschaften können wir die stochastische Dominanz ebenso charakterisieren:
%
%\begin{lemma}
%\label{lemmaStochastischeAequivalenz}
%Seien $X,Y$ nichtnegative Zufallsvariablen. Dann sind folgende Bedingungen äquivalent:
%\begin{enumerate}[ label=\alph*)]
	%\item Es gilt $X\leq_{st}Y$.
	%
	%\item Es existieren Zufallsvariablen $\tilde{X} \stackrel{D}{=} X$ und $\tilde{Y} \stackrel{D}{=} Y$, so dass $\Pro\left(\tilde{X}\leq\tilde{Y}\right)=1$ gilt.
	%
	%\item Es gilt $\EW\left(u(X)\right)\leq\EW\left(u(Y)\right)$ für jede monoton wachsende Funktion $u:\Rplus \to \mathbb{R}$.
%\end{enumerate}
%\end{lemma}

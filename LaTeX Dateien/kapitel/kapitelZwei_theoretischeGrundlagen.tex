\chapter{Theoretische Grundlagen für die Modellierung}

In diesem Kapitel sollen die in der Arbeit verwendeten mathematischen Hilfsmittel vorgestellt werden und die wichtigsten Eigenschaften bewiesen werden. Dabei werden Grundlegende Kenntnisse im Bereich der Wahrscheinlichkeitstheorie vorausgesetzt und dass Begriffe wie Wahrscheinlichkeitsraum, Zufallsvariable, Dichte- und Verteilungsfunktion bekannt sind. Im Folgenden ist der Wahrscheinlichkeitsraum immer definiert durch $(\Omega,\mathfrak{A},\mathbb{P})$.
\\

\section{Verwendete Verteilungen}
Zunächst werden wir die Verteilungen vorstellen, die in dieser Arbeit verwendet werden, und die wichtigsten Eigenschaften vorstellen.
\\

\begin{defini}
Eine Zufallsvariable $X:\Omega\to \mathbb{R}$ heißt \textbf{exponentialverteilt zum Parameter $\lambda$} (kurz: $\sim exp(\lambda)$) wenn sie die folgende Dichtefunktion besitzt:
	\begin{eqnarray*}
		f(x)=
		\begin{cases}
			\lambda e^{-\lambda x} & \text{für } x\geq 0 \\ 	
			0 & \text{für } x<0 \\ 
		\end{cases}
	\end{eqnarray*}
\end{defini}

\begin{figure}[ht]
   \centering
      \subfloat[Dichtefunktion]{\includegraphics[width=0.39\textwidth]{./bilder/ExpDichteF}}\qquad
      \subfloat[Verteilungsfunktion]{\includegraphics[width=0.39\textwidth]{./bilder/ExpVerteilungF}}
   \caption[Dichte- und Verteilungsfunktion der Exponentialverteilung]{Dichte- und Verteilungsfunktion der Exponentialverteilung}
\end{figure}

Die Exponentialverteilung hat folgende Eigenschaften:

\begin{enumerate}[label=(\roman{*})]
	\item Die Verteilungsfunktion der Exponentialverteilung ist: 
	\begin{eqnarray*}
		F_{\lambda}(x) = \int_{-\infty}^{x} f_{\lambda}(t) dt =
		\begin{cases}
			1-e^{-\lambda x} & \text{für } x\geq 0 \\ 	
			0 & \text{für } x<0 \\ 
		\end{cases}
	\end{eqnarray*}
	\item Der Erwartungswert ist:
	\begin{eqnarray*}
			\mathbb{E}(X) = \int_0^{\infty}\lambda xe^{-\lambda x} dx 
										= \left[-\frac{e^{-\lambda x}(\lambda x +1)}{\lambda}\right]^{\infty}_0
										= \frac{1}{\lambda}
	\end{eqnarray*}
	\item Die Varianz ist: 
	\begin{eqnarray*}
		Var(X) = \int_{\infty}^{0} \left(x-\frac{1}{\lambda}\right)^2 \lambda e^{-\lambda x} dx = \frac{1}{\lambda^2}
	\end{eqnarray*}
	\item Die Exponentialverteilung ist gedächtnislos (auch Nichtalterungseigenschaft genannt), d.h.:
	\begin{eqnarray*}
		F(x|t) := \mathbb{P}(x+t\leq X , t<X) &=& \frac{\mathbb{P}(t<X<x+t)}{\mathbb{P}(t<X)} \\
					 &=& \frac{\mathbb{P}(X\leq x+t) - \mathbb{P}(t\leq X)}{1-\mathbb{P}(t\leq X)} \\
					 &=& \frac{1-e^{-\lambda (x+t)} - (1-e^{-\lambda t})}{1-(1-e^{-\lambda t})} \\
					 &=& \frac{-e^{-\lambda x -\lambda t} + e^{-\lambda t}}{e^{-\lambda t}} \\
					 &=& \frac{e^{-\lambda t}(1-e^{-\lambda x})}{e^{-\lambda t}} \\
					 &=& 1-e^{-\lambda x} = \mathbb{P}(x\leq X) = F(x)
	\end{eqnarray*}
\end{enumerate}

Es lässt sich sogar zeigen, dass die Exponentialverteilung die einzige stetige Verteilung\footnote{Im diskreten Fall ist dies die geometrische Verteilung.} mit Nichtalterungseigenschaft ist:

\begin{lemmas} \label{expLemma} Wenn die Überlebenswahrscheinlichkeit ($\overline{F}(x) := 1-F(x)$) einer nicht ausgearteten, nicht negativen Zufallsvariable X der folgenden Beziehung genügt:
  \begin{equation}
		\mathbb{P}(x+t\leq X) = \mathbb{P}(x\leq X)\mathbb{P}(t\leq X)	\label{eq:lemma1}
	\end{equation}
dann gilt $X\sim exp(\lambda)$ für ein $\lambda >0$.
\end{lemmas}

\textbf{Beweis:}
Mit der Definition $f(x) := \mathbb{P}(x<X)$ lässt sich \ref{eq:lemma1} zu folgender Gleichung umformen
	\begin{eqnarray*}
		f(x+t) = f(x)f(t) \text{, mit} f(0) = \mathbb{P}(0\leq X) = 1
	\end{eqnarray*}
die sich wie folgt umformen lässt:
	\begin{eqnarray*}
		ln(f(x+t)) = ln(f(x)) + ln(f(t))
	\end{eqnarray*}
Unter der Voraussetzung, das die Dichte $p_X(t) = -f(t+0), t\geq 0$ existiert, ergibt sich durch Differentiation nach t:
	\begin{eqnarray*}
		\frac{f^{'}(x+t)}{f(x+t)} = \frac{f^{'}(t)}{f(t)} 
	\end{eqnarray*}
Für $t=0$ folgt damit:
	\begin{eqnarray*}
		\frac{f^{'}(x)}{f(x)} = f^{'}(t)
	\end{eqnarray*}
Da $f(0) = 1$ der maximale Wert der Funktion f(x) ist, gilt $0\geq f^{'}(0) := -\lambda$ und damit erhalten wir die bekannte Differentialgleichung:
	\begin{alignat*}{2}
		&& f^{'}(x) &= -\lambda f(x) \\
		&\Rightarrow & f(x) &= e^{-\lambda x} \\
		&\Rightarrow & F(x) &= 1-f(x) = 1-e^{-\lambda x} \\
		&\Rightarrow & X &\sim exp(\lambda)
	\end{alignat*}
\qed

\begin{defini}
Eine diskrete Zufallsvariable $X:\Omega\to \mathbb{N}$ heißt \textbf{Poisson-verteilt zum Parameter $\lambda \in \mathbb{R}_{>0}$} (kurz $X\sim Poi(\lambda)$), wenn gilt:
\begin{eqnarray*}
	\mathbb{P}(X=k) = \frac{\lambda^k}{k!}e^{-\lambda}, k=0,1,2,...
\end{eqnarray*}
\end{defini}

Die Poisson-Verteilung hat folgende Eigenschaften:

\begin{enumerate}[label=(\roman{*})]
	\item Die Verteilungsfunktion der Poisson-Verteilung ist: 
	\begin{eqnarray*}
		F_{\lambda}(n) = \sum_{k=0}^{n} \mathbb{P}_{\lambda}(k) = e^{-\lambda} \sum_{k=0}^{n} \frac{\lambda^k}{k!}
	\end{eqnarray*}
	\item Der Erwartungswert ist:
	\begin{eqnarray*}
			\mathbb{E}(X) &=& \sum_{k=0}^{\infty} k\frac{\lambda^k}{k!} e^{-\lambda}  
										=  0 + \sum_{k=1}^{\infty} k\frac{\lambda^k}{k!} e^{-\lambda} \\
										&=& \lambda e^{-\lambda} \sum_{k=1}^{\infty} \frac{\lambda^{k-1}}{(k-1)!} \\
										&=& \lambda e^{-\lambda} \sum_{i=0}^{\infty} \frac{\lambda^i}{i!} 
										= \lambda e^{-\lambda} e^{\lambda} 
										= \lambda
	\end{eqnarray*}
	
	Der Parameter $\lambda$ der Poisson-Verteilung kann also, als die erwartete Ereignishäufigkeit pro Zeiteinheit interpretiert werden.
	
	\item Die Varianz ist: 
	\begin{eqnarray*}
		\mathbb{E}(X^2) &=& \sum_{k=0}^{\infty} k^2 \frac{\lambda^k}{k!} e^{-\lambda} \\
										&=& e^{-\lambda} \sum_{k=1}^{\infty} k \frac{\lambda^{k}}{(k-1)!} \\
										&=& e^{-\lambda} \sum_{k=2}^{\infty} \frac{\lambda^{k}}{(k-2)!} + e^{-\lambda} \sum_{k=1}^{\infty} \frac{\lambda^{k}}{(k-1)!} \\
										&=& \lambda^2 e^{-\lambda} \sum_{k=2}^{\infty} \frac{\lambda^{k-2}}{(k-2)!} + \lambda e^{-\lambda} \sum_{1}^{\infty} \frac{\lambda^{k-1}}{(k-1)!} \\
										&=& \lambda^2+\lambda \\ \\
						 Var(X) &=& \mathbb{E}(X^2) - \mathbb{E}(X)^2 = \lambda^2+\lambda - \lambda^2 = \lambda
	\end{eqnarray*}
	\item Seien $X_1$ und $X_2$ unabhängige poissonverteilte Zufallsvariablen mit $X_1\sim Poi(\lambda _1)$ und $X_2\sim Poi(\lambda _2)$, dann gilt für $X := X_1 + X_2 $:
		\begin{eqnarray*}
			\mathbb{P}(X=x) &=& \sum_{k=0}^{x} \mathbb{P}(X_1=k)\mathbb{P}(X_2=x-k) \\
											&=& e^{-\lambda_1}e^{-\lambda_2} \sum_{k=0}^{x} \frac{\lambda _{1} ^k}{k!} \frac{\lambda _{2} ^{x-k}}{(x-k)!} \\
											&=& \frac{e^{-(\lambda_1+\lambda_2)}}{x!} \sum_{k=0}^{x} \frac{x!}{k!(x-k)!}\lambda _{1}^k \lambda _{2}^{x-k} \\
											&=& e^{-(\lambda_1+\lambda_2)} \frac{(\lambda _{1} + \lambda _{2})^x}{x!} \\
				\Rightarrow  X &\sim & Poi(\lambda _1 + \lambda _2) 
		\end{eqnarray*}
		Das heißt die Summe von poissonverteilten Zufallsvariablen ist wieder poissonverteilt.
	\end{enumerate}

Die Poisson-Verteilung hat außerdem eine besondere Bedeutung, da sie unter den richtigen Voraussetzungen die Grenzverteilung der Binomialverteilung ist. Dieser Zusammenhang wird in folgendem Lemma verdeutlicht: \\

\begin{lemmas} Die Poisson-Verteilung ist die Grenzverteilung der Binomial-Verteilung $B_{n,p}(k)$, wenn für die Erfolgswahrscheinlichkeit $p$ gilt $p\rightarrow 0$ und für die Anzahl der Versuche $n$ gilt $n\rightarrow \infty$ und außerdem für das Produkt $\lambda := np$ gilt $\lambda \neq 0$ und $\lambda \neq \infty$. 
\end{lemmas}

\textbf{Beweis:}
Entsprechend der Nebenbedingung können wir $p$ durch $\frac{\lambda}{n}$ ersetzen und damit ist die Bedingung $p\rightarrow 0$ äquivalent zu $n\rightarrow \infty$ und wir müssen somit nur einen Grenzwert bestimmen. Wir zeigen, dass der Grenzwert $n\rightarrow \infty$ einer binomialverteilten Zufallsvariable an der Stelle k, gegen den Wert einer poissonverteilten Zufallsvariablen an der Stelle k geht. 
	\begin{eqnarray*}
		\lim_{n\rightarrow \infty} \mathbb{P}(X=k) &=& \lim_{n\rightarrow \infty} \frac{n!}{k!(n-k)!} \left(\frac{\lambda}{n}\right)^k \left(1-\frac{\lambda}{n}\right)^{n-k} \\
		&=& \lim_{n\rightarrow \infty} \frac{\lambda ^k}{k!} \frac{n(n-1)(n-2)...(n-k+1)}{n^k} \left( 1-\frac{\lambda}{n}\right)^{n} \left(1-\frac{\lambda}{n}\right)^{-k} \\
		&=& \frac{\lambda ^k}{k!} * 1 * e^{-\lambda} * 1 \\
		&=& \frac{\lambda ^k e^{-\lambda}}{k!}		
	\end{eqnarray*}
\qed
	
\section{Poisson Prozess}	
Ein weiteres Hilfsmittel, dass zur Modellierung verwendet wird, sind Stochastische Prozesse. Diese eignen sich sehr gut dazu geordnete zufällige Vorgänge zu beschreiben. 
\\ 
	
\begin{defini}
Sei $(Z, \mathcal{Z})$ ein mit einer $\sigma$-Algebra versehener Raum, dann ist ein \textbf{Stochastischer Prozess $X$} ist eine Familie von Zufallsvariablen $\{X_t\}$ mit $X_t:\Omega\to Z, t\in T$. Für die Indexmenge T gilt in der Regel $T\in \{\mathbb{R}_{\geq 0}, \mathbb{N}_0\}$. Das heißt $X$ ist eine Abbildung
\begin{eqnarray*}
	X:\Omega \times T \to Z, \; (\omega, t) \mapsto X_t(\omega)
\end{eqnarray*}
sodass $X_t: \omega \mapsto X_t(\omega)$ für alle  $t \in T$ eine messbare Abbildung ist. Z heißt dann die \textbf{Zustandsmenge} und $(Z, \mathcal{Z})$ der \textbf{Zustandsraum}.
\end{defini}

\begin{enumerate}[label=(\roman{*})]
	\item Ein stochastische Prozess heißt \textbf{zeitdiskret}, wenn $T$ abzählbar ist, z.B. $T = \mathbb{N}_0$. Ansonsten heißt er \textbf{zeitstetig}. 
	Analog heißt ein Prozess mit diskreten Zustandsraum Z \textbf{wertdisktret} oder auch \textbf{Punktprozess}. 
	\item Ein stochastische Prozess heißt \textbf{stationär}, wenn für alle $s>0$, sowie $t_1,t_2,...,t_k\in T$ und $x_1,x_2,...,x_k \in Z$ gilt:
		\begin{eqnarray*}
			\mathbb{P}(X_{t_1+s}=x_1, X_{t_2+s}=x_2,..., X_{t_k+s}=x_k)=\mathbb{P}(X_{t_1}=x_1, X_{t_2}=x_2,..., X_{t_k}=x_k)				
		\end{eqnarray*}
		Das heißt, das zufällige Verhalten des Prozesses hängt nicht vom Zeitpunkt der Beobachtung ab.
	\item Ein stochastischer Prozess besitzt \textbf{Unabhängige Zuwächse}, wenn die Zufallsvariablen $X_{t_0},X_{t_1}-X_{t_0},...,,X_{t_n}-X_{t_{n-1}}$ für alle n=1,2,... und $0\leq t_0<t_1<...<t_n$ unabhängig sind.
\end{enumerate}

\begin{defini}
Sei $T_1, T_2, ... : \omega \rightarrow [0, \infty)$ eine Folge von unabhängig und identisch verteilten Zufallsvariablen, dann ist $N := \{N_t, t\geq 0\}$ mit
\begin{eqnarray*}
		N_t = \sum_{k=1}^{\infty} \mathbb{I}(S_k\leq t) \text{ und } S_n = T_1+...+T_n 
\end{eqnarray*}
ein stochastischer Prozess und wird als Zählprozess bezeichnet. 
\end{defini}

Prozesse dieser Art werden z.B. in der Zuverlässigkeitstheorie eingesetzt um die Ausfälle einer Komponente in einem bestimmten Zeitraum zu zählen. Deshalb werden die $T_n$ häufig als \textbf{Zwischenankunftszeiten} bezeichnet.

\begin{defini} \label{poiPro}
Ein Zählprozess $\{N_t, t\geq 0\}$ mit exponentialverteilten Zwischenankunftszeiten $T_n \sim exp(\lambda)$ heißt \textbf{homogener Poisson-Prozess mit der Intensität $\lambda$}.  
\end{defini}

In dem nachfolgendem Theorem werden die wichtigsten Eigenschaften und äquivalenten Definitionen des Poisson-Prozesses deutlich. Vorher benötigen wir jedoch folgende Definition: \\
%Wir schreiben $f(h) = o(g(h))$  (für $h \rightarrow 0$), falls $\lim_{h \rightarrow 0} f(h)/g(h) = 0$ und $f(h) = O(g(h)$, falls $|f(h)/g(h)|$ für $h \leq 1$ beschränkt ist. 

\begin{defini}
Seien $X_1, X_2,..., X_n$ Zufallsvariablen, dann bezeichnen wir die geordneten Variablen $X_{1:n} \leq X_{2:n} \leq ... \leq X_{n:n}$ als die \textbf{Ordnungsstatistik} der Variablen $\{X_i: 1 \leq i \leq n\}$.
\end{defini}

\begin{theorem} Die folgenden Aussagen sind äquivalent\footnote{Quelle siehe: \url{http://www.mathematik.uni-ulm.de/stochastik/lehre/ss05/wt/skript/node15.html}}:
\begin{enumerate}[label=(\roman{*})]
	\item $\{N_t, t\geq 0\}$ ist ein Poisson-Prozess mit der Intensität $\lambda$
	\item Die Zufallsvariablen $N_t$ sind poissonverteilt zum Parameter $\lambda t$ für alle $t\geq 0$. \\
	
	Unter der Bedingung $\{N_t = n\}$, hat für beliebige $n=1,2,...$ der Zufallsvektor $(S_1, S_2,...,S_n)$, die gleiche Verteilung wie die Ordnungsstatistik von n unabhängigen, in $[0,t]$ gleichverteilten Zufallsvariablen.
	\item Der stochastische Prozess $\{N_t, t\geq\}$ hat unabhängige Zuwächse und es gilt $\mathbb{E}(N_1) = \lambda$. \\
	
	Unter der Bedingung $\{N_t = n\}$, hat für beliebige $n=1,2,...$ der Zufallsvektor $(S_1, S_2,...,S_n)$, die gleiche Verteilung wie die Ordnungsstatistik von n unabhängigen, in $[0,t]$ gleichverteilten Zufallsvariablen.
	\item Der stochastische Prozess $\{N_t, t\geq\}$ hat unabhängige Zuwächse und ist stationär und es gilt für $h \rightarrow 0$:
	\begin{eqnarray*}
		\mathbb{P}(N_h =0) &=& 1-\lambda h + o(h) \text{, und} \\
		\mathbb{P}(N_h =1) &=& \lambda h + o(h)\
	\end{eqnarray*}
	\item Der stochastische Prozess $\{N_t, t\geq\}$ hat unabhängige Zuwächse und ist stationär. Außerdem gilt für jedes $t\geq 0$ das $N_t \sim Poi(\lambda t)$.
\end{enumerate}
\end{theorem}

\textbf{Beweis:} 
Da der Beweis sehr umfangreich ist, werden an dieser Stelle nur die wesentliche Schritte vorgestellt. \\
\begin{itemize}
\item $(i) \Rightarrow (ii)$:
	Aus $(i)$ folgt, dass $S_n=\sum_{i=1}^n T_i$ eine Summe von $n$ unabhängigen und zum Parameter $\lambda$ exponentialverteilten Zufallsvariablen ist, 	d.h., $S_n \sim Erl(n,\lambda)$, wobei $Erl(n,\lambda)$ die Erlang-Verteilung mit den Parametern $n$ und $\lambda$ bezeichnet. Hieraus folgt $\mathbb{P}(N_t = 0) = \mathbb{P}(S_1 > t) = e^{-\lambda t}$ und damit folgt:

\begin{eqnarray*}	 
	\mathbb{P}(N_t = n) &=&\mathbb{P}(N_t \geq n) - \mathbb{P}(N_t \geq n+1) \\	 
				&=&\mathbb{P}(S_n \leq t)- \mathbb{P}(S_{n+1} \leq t) \\
				&=&\int_0^t \frac{\lambda^n v^{n-1}}{(n-1)!} e^{-\lambda v} \mathrm{d}v - \int_0^t \frac{\lambda^{n+1}v^n}{n!} e^{-\lambda v} \mathrm{d}v	 \\
				&=&\int_0^t \frac{\mathrm{d}}{\mathrm{d}v} \left(\frac{(\lambda v)^n}{n!} e^{-\lambda v}\right) \mathrm{d}v \\
				&=&\frac{(\lambda t)^n}{n!} e^{-\lambda t}
\end{eqnarray*}

Dies gilt für jedes $n\geq 1$, und damit folgt, dass $N_t \sim Poi(\lambda t)$. Dies ist der erste Teil von $(ii)$ und für den zweiten Teil betrachten wir die gemeinsame Dichte $f_{S_1,...,S_{n+1}}(t_1,...,t_{n+1})$ von $S_1,...,S_{n+1}$. Diese ist für beliebige $t_0=0 \leq t_1 \leq ... \leq t_n \leq t_{n+1}$ gegeben durch

\begin{eqnarray*}	 
	f_{S_1,...,S_{n+1}}(t_1,...,t_{n+1}) = \prod_{k=1}^{n+1} \lambda e^{-\lambda(t_k-t_{k-1})} = \lambda^{n+1}e^{-\lambda t_{n+1}}
\end{eqnarray*}

und 0 sonst. Somit gilt unter der Bedingung $N_t=n$ und $0 \leq t_1 \leq ... \leq t_n \leq t$ für die gemeinsame bedingte Dichte

\begin{eqnarray*}	 
	f_{S_1,...,S_n}(t_1,...,t_n|N_t=n) &=& f_{S_1,...,S_n}(t_1,...,t_n|S_1 \leq t_1,...,S_n\leq t, S_{n+1} > t) \\
																						&=& \frac{\int_t^{\infty} \lambda^{n+1} e^{-\lambda x_{n+1}} dx_{n+1}}
																						{\int_0^t \int_{x_1}^t .. .\int_{x_{n-1}}^t \int_t^{\infty} \lambda^{n+1} e^{-\lambda x_{n+1}} dx_{n+1}...dx_1} \\
																						&=& \frac{n!}{t^n}
\end{eqnarray*}

und $f_{S_1,...,S_n}(t_1,...,t_n|N_t=n) = 0$ sonst. Dies ist die Dichte der Ordnungsstatistik von n unabhängigen in[0,t] gleichverteilten Zufallsvariablen und damit der zweite Teil dieses Beweisschritts. 

\item $(ii) \Rightarrow (iii)$: 

Aufgrund von $(ii)$ gilt $N_t \sim Poi(\lambda t)$ und damit ist $\mathbb{E} N_1 = \lambda$. Seien $x_1,...,x_n \in \mathbb{N}$ und $t_0=0 \leq t_1 \leq ... \leq t_n$, dann gilt für $x=x_1+...+x_n$

\begin{eqnarray*}	 
	\mathbb{P}(\bigcap_{k=1}^n\{N_{t_k}-N_{t_{k-1}}=x_k\})&=& \mathbb{P}(N_{t_1}-N_{t_0} = x_1,...,N_{t_n}-N_{t_{n-1}} = x_n)\\
	&=& \mathbb{P}(N_{t_1}-N_{t_0} = x_1,...,N_{t_n}-N_{t_{n-1}} = x_n | N_{t_n}=x)\mathbb{P}(N_{t_n}=x)\\
	&=& \frac{(\lambda t_n)^x}{x!}e^{-\lambda t_n} \frac{x!}{x_1!...x_n!} \prod_{k=1}^n \left(\frac{t_k-t_{k-1}}{t_n}\right)^{x_k} \\
	&=& \prod_{k=1}^n \frac{(\lambda (t_k-t_{k-1}))^{x_k}}{x_k!} e^{-\lambda (t_k - t_{k-1})}
\end{eqnarray*}

und damit hat der Zählprozess ${N_t}$ unabhängige Zuwächse.

\item $(iii) \Rightarrow (iv)$: 

Aus $(iii)$ folgt, dass der Zufallsvektor $(S_1,...,S_m)$, unter der Bedingung $N(t_n + h) = m$, die gleiche Verteilung hat, wie die Ordnungstatistik vom m unabhängigen in $[0, t_n + h]$ gleichverteilten Zufallsvariablen hat. Deshalb gilt für beliebige $x_1,...,x_n \in \mathbb{N}$, $t_0=0 \leq t_1 \leq ... \leq t_n$ und$h>0$ 

\begin{eqnarray*}	 
	\mathbb{P}(\bigcap_{k=1}^n\{N_{t_k+h}-N_{t_{k-1}+h}=x_k\}|N_{t_n}+h=m)
	= \mathbb{P}(\bigcap_{k=1}^n\{N_{t_k}-N_{t_{k-1}}=x_k\}|N_{t_n}+h=m)
\end{eqnarray*}

Aufgrund der Formel der totalen Wahrscheinlichkeit folgt damit, dass ${N_t}$ stationär ist. Die Gleichverteilungseigenschaft aus $(iii)$ liefert außerdem für $0<h<1$

\begin{eqnarray*}	 
	\mathbb{P}(N_h=0) &=& \sum_{k=0}^\infty \mathbb{P}(N_h=0,N_1-N_h=k)\\
		&=& \sum_{k=0}^\infty \mathbb{P}(N_1=k)\mathbb{P}(N_1-N_h=k|N_1=k)\\
		&=& \sum_{k=0}^\infty \mathbb{P}(N_1=k)(1-h)^k
\end{eqnarray*}

und somit gilt

\begin{eqnarray*}	 
	\frac{1}{h}(1-\mathbb{P}(N_h=0)) &=& \frac{1}{h}\left(1-\sum_{k=0}^\infty \mathbb{P}(N_1=k)(1-h)^k\right)\\
		&=& \sum_{k=1}^\infty \mathbb{P}(N_1=k) \frac{1-(1-h)^k}{h}
\end{eqnarray*}

Da $(1-h)^k\geq1-kh$ für beliebige $0<h<1$ und $k=1,2,...$ gilt, folgt, dass die Funktionen $g_h(k)=\frac{1-(1-h^k)}{h}$ die gemeinsame Schranke $g(k)=k$ besitzen.
Diese Schranke ist integrierbar, da gilt

\begin{eqnarray*}	 
	\sum_{k=1}^\infty k\mathbb{P}(N_1=k) = \mathbb{E}(N_1) = \lambda < \infty .
\end{eqnarray*}

Durch die Vertauschung von Summe und Grenzwert, ergibt sich

\begin{eqnarray*}	 
	\lim_{h \rightarrow 0} \frac{1}{h} \mathbb{P}(N_h>0) = \lambda
\end{eqnarray*}

und damit der erste Grenzwert von $(iv)$. Analog dazu gilt

\begin{eqnarray*}	 
	\lim_{h \rightarrow 0} \frac{1}{h} \mathbb{P}(N_h=1) = \lim_{h \rightarrow 0} \sum_{k=1}^\infty \mathbb{P}(N_1=k)k(1-h)^{k-1} = \lambda
\end{eqnarray*}

was äquivalent zur zweiten Bedingung in $(iv)$ ist.

\item $(iv) \Rightarrow (v)$: 

Sei $\mathbb{P}(N_t=n) := p_n(t)$ mit $n\in \mathbb{N}$ und $t\geq0$, dann gilt für $h>0$

\begin{eqnarray} \label{eq:th1a}
	p_0(t+h)=\mathbb{P}(N_t=0,N_{t+h}-N_t=0)=p_0(t)(1-\lambda h + o(h))
\end{eqnarray}

und für $t\geq h>0$

\begin{eqnarray} \label{eq:th1b} 
	p_0(t)=p_0(t-h)(1-\lambda h + o(h))
\end{eqnarray}

Damit ist $p_0(t)$ stetig in $(0,\infty)$ und rechtsstetig im Punkt $t=0$. Da $p_0(t-h)=p_0(t)+o(1)$ folgt aus \ref{eq:th1a} und \ref{eq:th1b}, dass für beliebige $h\geq -t$ gilt

\begin{eqnarray*}	 
	\frac{p_0(t+h)-p_0(t)}{h}=-\lambda p_0(t) + o(1)
\end{eqnarray*}

Das zeigt das $p_0(t)$ differenzierbar ist und es ergibt sich für t>0 folgende Differenzialgleichung

\begin{eqnarray*}	 
	p_0'(t)=-\lambda p_0(t).
\end{eqnarray*}

Durch die Randbedingung $p_0(0) = \mathbb{P}(N_0=0) = 1$ ist die eindeutig bestimmte Lösung 

\begin{eqnarray*}	 
	p_0(t)= e^{-\lambda t} , t\geq 0.
\end{eqnarray*} 

Für beliebige $n\in \mathbb{N}$ gilt 

\begin{eqnarray*}	 
	p_n(t)= \frac{(\lambda t)^n}{n!}e^{-\lambda t} , t\geq 0.
\end{eqnarray*} 

Dies lässt sich analog zum vorherigen Fall zeigen und durch vollständige Induktion nach n folgt $(v)$.

\item $(v) \Rightarrow (i)$:
 
Sei $ b_0 = 0 \le a_1 < b_1 \leq ...\leq a_n < b_n$, dann gilt 

\begin{eqnarray*}	 
	&& \mathbb{P}(\cap_{k=1}^n\{ a_k < S_k \leq b_k\})	= \\[6pt]
	&& \mathbb{P}(\cap_{k=1}^{n-1}\{N_{a_k} -N_{b_{k-1}} = 0, N_{b_k} - N_{a_k} = 1\} \cap \{N_{a_n} - N_{b_{n-1}} = 0, N_{b_n} - N_{a_n} \geq 1\})
\end{eqnarray*} 

und zusammen mit $(v)$ 

\begin{eqnarray*}
	&& \mathbb{P}(\cap_{k=1}^n\{ a_k < S_k \leq b_k\}) \\
	&=& e^{-\lambda(a_n - b_{n-1})} (1 - e^{-\lambda(b_n - a_n)}) \prod_{k=1}^{n-1} e^{-\lambda(a_k - b_{k-1})} \lambda (b_k -a_k) e^{-\lambda(b_k - a_k)} \\
	&=& (e^{-\lambda a_n} - e^{-\lambda b_n})\lambda^{n-1} \prod_{k=1}^{n-1} (b_k - a_k) \\
	&=& \int_{a_1}^{b_1}...\int_{a_n}^{b_n} \lambda^n e^{-\lambda y_n} dy_n...dy_1 \\
	&=& \int_{a_1}^{b_1}\int_{a_2 - x_1}^{b_2 - x_1}...\int_{a_n-x_1-...-x_{n-1}}^{b_n-x_1-...-x_{n-1}} \lambda^n e^{-\lambda(x_1 +...+x_n)} dx_n...dx_1
\end{eqnarray*}

Die gemeinsame Dichte von  $ S_1, S_2 - S_1, ...,S_n - S_{n-1}$ ist somit gegeben durch

\begin{eqnarray*}
	\mathbb{P}(\cap_{k=1}^n \{S_k-S_{k-1}\in dx_k\})=\lambda^n e^{-\lambda(x_1 + ... +x_n)}dx_1...dx_n.
\end{eqnarray*}

Dies bedeutet, dass die Zufallsvariablen  $ S_1, S_2 - S_1, ...,S_n - S_{n-1}$ unabhängig und Exp($ \lambda$)-verteilt sind, d.h., $ \{N_t\}$ ist ein Poisson-Prozess mit der Intensität $ \lambda$. 

\end{itemize}
\qed

Die folgende sehr nützliche Eigenschaft ist bereits von der Poisson-Verteilung bekannt:

\begin{lemmas} \label{lem:zusammengesetzterPP}
Die Überlagerung von zwei unabhängigen Poisson-Prozessen $\{N_t^1, t\geq 0\}$ und $\{N_t^1, t\geq 0\}$  mit der Intensität $\lambda _1$ bzw. $\lambda _2$ ist wieder ein Poisson-Prozess mit Intensität $\lambda = \lambda _1+\lambda _2$.
\end{lemmas}
\textbf{Beweis:} 
Im vorangegangen Theorem hab wir gezeigt, dass für einen Poisson-Prozess $\{N_t, t\geq 0\}$ gilt $N_t \sim Poi(\lambda t)$. Da $\{N_t^1, t\geq 0\}$ und $\{N_t^1, t\geq 0\}$ unabhängig sind gilt für die Summe $N_t^1 + N_t^2 \sim Poi((\lambda _1 + \lambda _2)t)$. Damit ist die Überlagerung der beiden Poisson-Prozesse wieder ein Poisson-Prozess mit Intensität $\lambda = \lambda _1+\lambda _2$.
\qed \\

Ein interessantes Phänomen ist zu beobachten, wenn bei sich bei einem Poisson-Prozess die Zeit bis zum nächsten Ereignis, zu einem beliebigen Zeitpunkt, betrachtet.
\begin{lemmas}\label{lem:wartezeit}
Sei $\{N_t, t\geq 0\}$ homogener Poisson-Prozess mit Intensität $\lambda$ und $W_t$ die Wartezeit ab dem Zeitpunkt t bis zum nächsten Ereignis. Dann ist $W_t \sim exp(\lambda)$, also insbesondere ist $\mathbb{E}(W_t) = \frac{1}{\lambda}$ für alle $t > 0$.
\end{lemmas}

\textbf{Beweis:} 
Da die Zwischenankunftszeiten eines Poisson-Prozesses exponentialverteilt sind, folgt der Beweis direkt aus der Gedächtnislosigkeit der Exponentialverteilung. Sei $S_k$ der Zeitpunkt des letzten Ereignisses, also $S_k<t<S_{k+1}$, und $w:= t-S_k$ die Wartezeit seit dem letzten Ereignis.
\begin{eqnarray*}
	\mathbb{P}(W_t>s) &=& \mathbb{P}(S_{k+1} - S_{k}>w+s | S_{k+1} - S_{k}>w) \\
	&=& \mathbb{P}(T_{k+1} >w+s | T_{k+1} > w) \\
	&=& \mathbb{P}(T_{k+1}>s) = e^{-\lambda s}
\end{eqnarray*}
D.h. die Wartezeit zum Zeitpunkt t ist genauso verteilt wie die Zwischenankunftszeiten und damit unabhängig davon, wie viel Zeit bereits seit dem letzten Ereignis vergangen ist.
\qed \\

\section{Markov-Kette}\label{sec:markov}
Als nächstes werden wir eine weitere wichtige Klasse an stochastischen Prozessen vorstellen. Dieser Abschnitt basiert zum Großteil auf dem Script von Professor König, "`Wahrscheinlichkeitstheorie II"' aus dem WS 06/07.

\begin{defini} 
Ein Stochastischer Prozess $\{X_t, t >0\}$ aus $I$-wertigen Zufallsvariablen, besitzt die \textbf{Markoveigenschaft}, wenn für $t_0, t_1,...t_n,t_{n+1} \in T$ und alle $i_0,i_1,...,i_{n+1} \in I$ gilt:
\begin{eqnarray*}
	\mathbb{P}(X_{t_{n+1}}=i_{n+1}|X_{t_n}=i_n,X_{t_{n-1}}=i_{n-1},...,X_{t_0}=i_0) = \mathbb{P}(X_{t_{n+1}}=i_{n+1}|X_{t_n}=i_n)
\end{eqnarray*}
Ein solcher Prozess heißt im stetigen Fall \textbf{Markovscher Prozess} und \textbf{Markov-Kette} im diskreten Fall. Die \textbf{Startverteilung} der Markov-Kette ist definiert durch $v(i) = \mathbb{P}(X_0 = i)$ und die Wahrscheinlichkeiten $\mathbb{P}(X_{t_{n+1}}=i_{n+1}|X_{t_n}=i_n) =: p_{i_n , i_{n+1}}$ werden als \textbf{Übergangswahrscheinlichkeiten} bezeichnet. Die Matrix $P = (p_{i,j})_{i, j \in I}$ die sich aus den Übergangswahrscheinlichkeiten ergibt heißt \textbf{Übergangsmatrix}.
\end{defini}

Der nächste Zustand einer Markov-Kette hängt also immer nur von dem aktuellen Zustand ab. D.h. die Kette wird durch die Übergangswahrscheinlichkeiten charakterisiert. Deshalb hat die Übergangsmatrix auch eine besondere Struktur. Im folgenden betrachten wir lediglich den stetigen Fall, d.h die Zustandsmenge $I$ ist eine nichtleere, endliche oder höchstens abzählbar unendliche Menge und die Indexmenge T ist eine Teilmenge von $\mathbb{N}$. 

\begin{defini} Eine Matrix $P = (p_{i,j})$ heißt \textbf{stochastisch}, falls für alle $i, j \in I$ (Indexmenge) gilt  $p_{i,j} \in [0, 1]$ und $\sum_{j \in I} p_{i,j} = 1$.
\end{defini}

Die Übergangsmatrix ist also eine stochastische Matrix, welche für jeden Zustand eine Zeile besitzt, in der die möglichen Übergänge des entsprechenden Zustands, in andere Zustände und die dazugehörigen Wahrscheinlichkeiten angegeben wird. 

\begin{lemmas}
Sei $\{X_n, n\in \mathbb{N}\}$ eine Folge von $I$-wertigen Zufallsgrößen, $v$ eine Verteilung auf $I$ und $P$ eine stochastische Matrix, dann ist $\{X_t,n\in \mathbb{N}\}$ genau dann eine Markov-Kette mit Übergangsmatrix $P$ und Startverteilung $v$, wenn für alle $n\in\mathbb{N}$ und alle $i_0,i_1,...,i_n \in I$ gilt
\begin{eqnarray}
\label{eq:markov1}
	\mathbb{P}(X_0=i_0,X_1=i_1,...,X_n=i_n) = v(i_0)p_{i_0,i_1}p_{i_1,i_2}...p_{i_{n-1},i_n}
\end{eqnarray}
\end{lemmas}

\textbf{Beweis:}
Der Beweis das die Gleichung \ref{eq:markov1} für eine Markov-Kette gilt, erfolgt leicht mithilfe von vollständiger Induktion nach n zusammen mit der Definition der Übergangswahrscheinlichkeiten. \\

Die andere Richtung folgt aus der Definition der bedingten Wahrscheinlichkeit:
\begin{eqnarray*}
	\mathbb{P}(X_{n+1}=i_{n+1}|X_0=i_0,...,X_n=i_n) &=& \frac{\mathbb{P}(X_{n+1}=i_{n+1})\mathbb{P}(X_0=i_0,...,X_n=i_n)}{\mathbb{P}(X_0=i_0,...,X_n=i_n)} \\
	&=& \frac{p_{n,n+1} v(i_0)p_{i_0,i_1}p_{i_1,i_2}...p_{i_{n-1},i_n}}{v(i_0)p_{i_0,i_1}p_{i_1,i_2}...p_{i_{n-1},i_n}} \\
	&=& p_{n,n+1} = \mathbb{P}(X_{n+1}=i_{n+1}|X_n=i_n)
\end{eqnarray*}
 
\qed

Als nächstes wollen wir mithilfe der Übergangsmatrix die Wahrscheinlichkeit dafür bestimmen, dass sich der Prozess nach n Schritten in einem bestimmten Zustand $j \in I$ befindet.\\

\begin{defini}
Sei $\{X_t, n\in \mathbb{N}\}$ eine Markov-Kette mit Übergangsmatrix $P$. Dann sind 
\begin{eqnarray*}
	\mathbb{P}(X_n+m=j,X_n=i) = P_{i,j}^n := p_{i,j}^{(n)}
\end{eqnarray*}
die \textbf{n-stufigen Übergangswahrscheinlichkeiten} für alle $n\in \mathbb{N}$ und alle $i, j\in I$. Das heißt die Wahrscheinlichkeit dafür, dass die Markov Kette in n Schritten vom Zustand $i$ in den Zustand $j$ bewegt, entspricht der n-ten Potenz der Übergangsmatrix an der Stelle $(i,j)$. 
\end{defini}

Es gibt verschiedene Eigenschaften die eine Markov-Kette haben kann, wenn die Übergangsmatrix eine besondere Struktur hat. Diese wollen wir an dieser Stelle vorführen.\\

\begin{defini} Im folgenden sei immer eine Markov-Kette $\{X_t, t\geq 0\}$ mit $I$-wertigen Zufallsgrößen und einer Übergangsmatrix $P$ gegeben. Außerdem seien $i, j \in I$ beliebige Zustand des Zustandsraums.

\begin{enumerate}[label=(\roman{*})]
	\item Eine Markov-Kette heißt irreduzibel, wenn für alle $i,j \in I$ ein $n \in \mathbb{N}$ existiert, so dass
		\begin{eqnarray*}
			\mathbb{P}(X_n=j|X_0=i) = p_{i,j}^{(n)} > 0.
		\end{eqnarray*}
	Das heißt jeder Zustand der Kette kann jeden anderen Zustand mit positiver Wahrscheinlichkeit erreichen.
                
	\item Sei $T_{i,j} := min\{n\in \mathbb{N} : X_n = i | X_0=i\}$ die Wartezeit bis die Markovkette vom Zustand $i$ aus, das erste Mal den Zustand $j$ erreicht. Ein Zustand i heißt heißt \textbf{rekurrent} falls $\mathbb{P}(T_i<\infty) = 1$, ansonsten heißt er \textbf{transient}. D.h. ein rekurrenter Zustand wird also mit Sicherheit in endlicher Zeit erneut erreicht.
	
	\item Ein Zustand $i$ heißt absorbierend, wenn $\mathbb{P}(X_{n+m} = j | X_n = i) = 0$ für alle $m\in \mathbb{N}$ und alle $j \in I$. Anlog heißt eine Menge $A\subset I$ absorbierend, wenn $\mathbb{P}(X_{n+m} \notin A | X_n \in A) = 0$. Das heißt eine Markov-Kette, die einen absorbierenden Zustand bzw. eine absorbierende Teilmenge von $I$ erreicht, kann diese nicht mehr verlassen.
	
	\item Die Startverteilung $v$ einer Markov-Kette heißt \textbf{stationär}, wenn gilt dass $\mathbb{P}(X_n=i) = v(i)$ für alle $n\in \mathbb{N}$ und alle $i$. Das heißt die Wahrscheinlichkeit hängt zu jedem Zeitpunkt nur von der Startverteilung ab. Anders ausgedrückt gilt $vP = v$, d.h. v ist ein Eigenvektor der Übergangsmatrix zum Eigenwert 1.
	
\end{enumerate}
\end{defini}

TODO:
\begin{itemize}
  \item Ergodizität
	\item Monte-Carlo-Simlation evtl. Markov-Chain-Monte-Carlo 
	\item Empirische Verteilung
\end{itemize}

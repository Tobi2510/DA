\section{Markov-Kette}\label{sec:markov}
Als nächstes werden wir eine weitere wichtige Klasse an stochastischen Prozessen vorstellen. Dieser Abschnitt basiert zum Großteil auf dem Skript von Professor Wolfgang König, "`Wahrscheinlichkeitstheorie I und II"' (\cite{scriptKoenig}). Für den gesamten Abschnitt gilt, dass $I$ eine nichtleere, endliche oder höchstens abzählbar unendliche Menge ist.

\begin{defini} 
Ein Stochastischer Prozess $\{X_n, n \in \mathbb{N}\}$ aus $I$-wertigen Zufallsvariablen besitzt die \textbf{Markoveigenschaft}, wenn für alle $n \in \mathbb{N}$ und alle $i_0,i_1,...,i_{n+1} \in I$ gilt:
\begin{eqnarray}
\label{eq:markov}
	\mathbb{P}(X_{n+1}=i_{n+1}\: | \:X_n=i_n,X_{n-1}=i_{n-1},...,X_0=i_0) = \mathbb{P}(X_{n+1}=i_{n+1}\: | \:X_n=i_n)
\end{eqnarray}

Ein diskreter stochastischer Prozess, der \eqref{eq:markov} erfüllt, heißt \textbf{Markov-Kette}. Die \textbf{Startverteilung} der Markov-Kette ist definiert durch $v(i) := \mathbb{P}(X_0 = i)$ und die Wahrscheinlichkeiten $\mathbb{P}(X_{n+1}=i_{n+1}\: | \:X_n=i_n) =: p_{i_n , i_{n+1}}$ werden als \textbf{Übergangswahrscheinlichkeiten} bezeichnet. Die Matrix $P = (p_{i,j})_{i, j \in I}$, die sich aus den Übergangswahrscheinlichkeiten ergibt, heißt \textbf{Übergangsmatrix}.
\end{defini}

Der nächste Zustand einer Markov-Kette hängt also immer nur von dem aktuellen Zustand ab. Das heißt, die Kette wird durch die Übergangswahrscheinlichkeiten charakterisiert. Deshalb hat die Übergangsmatrix auch eine besondere Struktur.

\begin{defini} Eine Matrix $P = (p_{i,j})$ heißt \textbf{stochastisch}, falls für alle $i, j \in I$ (Indexmenge) gilt  $p_{i,j} \in [0, 1]$ und $\sum_{j \in I} p_{i,j} = 1$.
\end{defini}

Die Übergangsmatrix ist also eine stochastische Matrix, welche für jeden Zustand eine Zeile besitzt, in der die möglichen Übergänge des entsprechenden Zustands in andere Zustände und die dazugehörigen Wahrscheinlichkeiten angegeben werden. 

\begin{lemmas}
Sei $\{X_n, n\in \mathbb{N}\}$ eine Folge von $I$-wertigen Zufallsgrößen, $v$ eine Verteilung auf $I$ und $P$ eine stochastische Matrix, dann ist $\{X_n,n\in \mathbb{N}\}$ genau dann eine Markov-Kette mit Übergangsmatrix $P$ und Startverteilung $v$, wenn für alle $n\in\mathbb{N}$ und alle $i_0,i_1,...,i_n \in I$ gilt
\begin{eqnarray}
\label{eq:markov1}
	\mathbb{P}(X_0=i_0,X_1=i_1,...,X_n=i_n) = v(i_0)p_{i_0,i_1}p_{i_1,i_2}...p_{i_{n-1},i_n}
\end{eqnarray}
\end{lemmas}

\textbf{Beweis:}
Der Beweis, dass die Gleichung \eqref{eq:markov1} für eine Markov-Kette gilt, erfolgt leicht mithilfe von vollständiger Induktion nach n zusammen mit der Definition der Übergangswahrscheinlichkeiten: \\

\textit{Induktionsanfang}: 
\begin{eqnarray*}
	\mathbb{P}(X_0=i_0) &=& v(i_0) \\
	\mathbb{P}(X_0=i_0, X_1=i_1) &=& v(i_0) * \mathbb{P}(X_1=i_1 \:|\: X_0=i_0) = v(i_0)*p_{i_0,i_1}									
\end{eqnarray*}

\textit{Induktionsschritt}:
\begin{eqnarray*}
	&& \mathbb{P}(X_0=i_0, X_1=i_1,...,X_{n+1}=i_{n+1}) \\
	&=& \frac{\mathbb{P}(X_0=i_0,X_1=i_1,...,X_{n+1}=i_{n+1})}{\mathbb{P}(X_0=i_0,X_1=i_1,...,X_n=i_n)} \mathbb{P}(X_0=i_0,X_1=i_1,...,X_n=i_n)\\
	&=& \mathbb{P}(X_{n+1}=i_{n+1} \: |\: X_0=i_0,X_1=i_1,...,X_n = i_n) * v(i_0)p_{i_0,i_1}p_{i_1,i_2}...p_{i_{n-1},i_n} \\
	&=& \mathbb{P}(X_{n+1}=i_{n+1}\:|\:X_n=i_n) * v(i_0)p_{i_0,i_1}p_{i_1,i_2}...p_{i_{n-1},i_n}\\
	&=& v(i_0)p_{i_0,i_1}p_{i_1,i_2}...p_{i_{n-1},i_n}*p_{i_n,i_{n+1}}						
\end{eqnarray*}

Die andere Richtung folgt aus der Definition der bedingten Wahrscheinlichkeit:

\begin{eqnarray*}
	\mathbb{P}(X_{n+1}=i_{n+1}\: | \:X_0=i_0,...,X_n=i_n) &=& \frac{\mathbb{P}(X_0=i_0,...,X_n=i_n, X_{n+1}=i_{n+1})}{\mathbb{P}(X_0=i_0,...,X_n=i_n)} \\
	&=& \frac{v(i_0)p_{i_0,i_1}p_{i_1,i_2}...p_{i_{n-1},i_n}p_{i_n,i_{n+1}}}{v(i_0)p_{i_0,i_1}p_{i_1,i_2}...p_{i_{n-1},i_n}} \\
	&=& p_{i_n,i_{n+1}} = \mathbb{P}(X_{n+1}=i_{n+1}\: | \:X_n=i_n)
\end{eqnarray*}
 
\qed

Als Nächstes wollen wir mithilfe der Übergangsmatrix die Wahrscheinlichkeit dafür bestimmen, dass sich der Prozess nach n Schritten in einem bestimmten Zustand $j \in I$ befindet.\\

\begin{lemmas} \label{lem:übergangsws}
Sei $\{X_n, n\in \mathbb{N}\}$ eine Markov-Kette im Zustand $i$ mit Übergangsmatrix $P$. Dann gilt für alle $n\in \mathbb{N}$ und alle $i, j\in I$
\begin{eqnarray*}
	p_{i,j}^{(n)} := \mathbb{P}(X_n=j,X_0=i) = (P^n)_{i,j}
\end{eqnarray*}
und die $p_{i,j}^{(n)}$ werden als \textbf{n-stufigen Übergangswahrscheinlichkeiten} bezeichnet. Das heißt die Wahrscheinlichkeit dafür, dass sich die Markov Kette in n Schritten vom Zustand $i$ in den Zustand $j$ bewegt, entspricht der n-ten Potenz der Übergangsmatrix an der Stelle $(i,j)$. 
\end{lemmas}

Bevor wir dieses Lemma beweisen können, benötigen wir noch folgenden Satz zu den Übergangswahrscheinlichkeiten:
\begin{satz} (\textbf{Chapman-Kolmogorov-Gleichung})
$\{X_n, n\in \mathbb{N}\}$ eine Markov-Kette dann gilt für alle $m, n\in \mathbb{N}$ und alle $i, j\in I$
\begin{equation} \label{eq:chapKol}
	p_{i,j}^{(m+n)} = \sum_{k\in I} p_{i,k}^{(m)}*p_{k,j}^{(n)}.
\end{equation}
\end{satz}

\textbf{Beweis:}
\begin{eqnarray*}
	p_{i,j}^{(m+n)} &=& \mathbb{P}(X_{n+m}=j,X_0=i) \\
									&=& \sum_{k \in I} \mathbb{P}(X_{m+n} = j, X_m =k \:|\: X_0=i) \\
									&=& \sum_{k \in I} \frac{\mathbb{P}(X_{m+n} = j, X_m =k, X_0=i)}{\mathbb{P}(X_0=i)} \\
									&=& \sum_{k \in I} \frac{\mathbb{P}(X_{m+n} = j, X_m =k, X_0=i)}{\mathbb{P}(X_m = k, X_0=i)}  \frac{\mathbb{P}(X_m = k, X_0=i)}{\mathbb{P}(X_0=i)}\\
									&=& \sum_{k \in I} \mathbb{P}(X_{m+n} = j \:|\: X_m =k, X_0=i) \mathbb{P}(X_m = k \:|\: X_0=i)\\
									&=& \sum_{k \in I} \mathbb{P}(X_{m+n} = j \:|\: X_m =k) \mathbb{P}(X_m = k \:|\: X_0=i)\\
									&=& \sum_{k \in I} \mathbb{P}(X_n = j \:|\: X_0 =k) \mathbb{P}(X_m = k \:|\: X_0=i)\\
									&=& \sum_{k \in I} p_{i,k}^{(m)}*p_{k,j}^{(n)}
\end{eqnarray*}
\qed

Mit Hilfe der Chapman-Kolmogorov-Gleichung können wir beweisen, dass die \textbf{n-stufigen Übergangswahrscheinlichkeiten} der n-ten Potenz der Übergangsmatrix an der Stelle $(i,j)$ entsprechen.\\

\textbf{Beweis: Lemma \ref{lem:übergangsws}}\\
Sei $P^{(n)} := \{p_{i,j}^{(n)}\}_{i,j\in I}$ die Matrix der n-stufigen Übergangswahrscheinlichkeiten, wobei $P^{(0)} := \mathbb{I}$ die Einheitsmatrix ist. Dann gilt aufgrund von \eqref{eq:chapKol}
\begin{eqnarray*}
	P^{(n+m)} = P^{(n)}*P^{(m)}.
\end{eqnarray*}

Für n>0 folgt dann
\begin{eqnarray*}
	P^{(n)} = P^{(1+n-1)} = P*P^{(n-1)}=...=P^n.
\end{eqnarray*}
\qed

Nun wollen wir die verschiedenen Eigenschaften vorstellen, die eine Markov-Kette haben kann, wenn die Übergangsmatrix eine besondere Struktur hat.\\

\begin{defini} Im folgenden sei immer eine Markov-Kette $\{X_n, n \in \mathbb{N}\}$ mit $I$-wertigen Zufallsgrößen und einer Übergangsmatrix $P$ gegeben. Außerdem seien $i, j \in I$ beliebige Zustände des Zustandsraums.

\begin{enumerate}[label=(\roman{*})]
	\item Eine Markov-Kette heißt irreduzibel oder ergodisch, wenn für alle $i,j \in I$ ein $n \in \mathbb{N}$ existiert, so dass
		\begin{eqnarray*}
			\mathbb{P}(X_n=j\: | \:X_0=i) = p_{i,j}^{(n)} > 0.
		\end{eqnarray*}
	Das heißt jeder Zustand der Kette kann jeden anderen Zustand mit positiver Wahrscheinlichkeit erreichen.
                
	\item Sei $T_{i,j} := min\{n\in \mathbb{N} : X_n = i \: | \: X_0=i\}$ die Wartezeit bis die Markov-Kette vom Zustand $i$ aus, das erste Mal den Zustand $j$ erreicht. Ein Zustand $i$ heißt \textbf{rekurrent} falls $\mathbb{P}(T_{i,i}<\infty) = 1$, ansonsten heißt er \textbf{transient}. D.h. ein rekurrenter Zustand wird also fast sicher in endlicher Zeit erneut erreicht. Eine Markov-Kette heißt rekurrent wenn alle ihre Zustände rekurrent sind.
	
	\item Sei $\mu _i := \mathbb{E}(T_{i,i}) = \sum_{n\in\mathbb{N}} n \mathbb{P}(T_{i,i} =n)$ die erwartete Rückkehrzeit zu einem Zustand $i$ bei Start in $i$. Ein Zustand $i$ heißt \textbf{positiv rekurrent}, falls $\mu _i < \infty$ und \textbf{nullrekurrent}, wenn $i$ rekurrent ist, aber nicht positiv rekurrent.
	
	\item Ein Zustand $i$ heißt absorbierend, wenn $\mathbb{P}(X_{n+m} = j \: | \: X_n = i) = 0$ für alle $m\in \mathbb{N}$ und alle $j \in I$. Anlog heißt eine Menge $A\subset I$ absorbierend, wenn $\mathbb{P}(X_{n+m} \notin A \: | \: X_n \in A) = 0$. Das heißt eine Markov-Kette, die einen absorbierenden Zustand bzw. eine absorbierende Teilmenge von $I$ erreicht, kann diese nicht mehr verlassen.
	
	\item Die Periode eines Zustands $i$ ist definiert als:
		\begin{eqnarray*}
			d_i = ggT\{n\geq 1 \: | \: p_{i,i}^{(n)}> 0\}.
		\end{eqnarray*}
		Ein Zustand heißt \textbf{aperiodisch}, wenn $d_i=1$ und \textbf{periodisch} sonst.
		
	\item Die Startverteilung $v$ einer Markov-Kette heißt \textbf{stationär} oder \textbf{Gleichgewichtsverteilung}, wenn für alle $n\in \mathbb{N}$ und alle $i$ gilt 
	\begin{equation} \label{eq:invariant}
		\mathbb{P}(X_n=i) = v(i).
	\end{equation}
	Das heißt die Wahrscheinlichkeit hängt zu jedem Zeitpunkt nur von der Startverteilung ab. Anders ausgedrückt gilt $vP = v$, d.h. v ist ein Eigenvektor der Übergangsmatrix zum Eigenwert 1. Ist $v$ ein beliebiges Maß mit der Eigenschaft \eqref{eq:invariant}, dann bezeichnen wir es als \textbf{invariantes Maß}. 
	
\end{enumerate}
\end{defini}

Die Gleichgewichtsverteilung kann nicht immer explizit angegeben werden, aber in einigen Sonderfällen ist dies möglich. Doch vorher benötigen wir noch folgenden Hilfsatz.

\begin{satz} Sei $\{X_n, n\in \mathbb{N}\}$ eine irreduzibel und rekurrente Markov-Kette, und sei $k \in I$. Weiterhin sei $\gamma_k$ ein Maß, das für die, in einem beliebigen Zustand $k\in I$ gestartete Markov-Kette, die erwartete Anzahl an Besuchen in einem Zustand $i \in I$ bis zur ersten Rückkehr der Kette nach $k$ zählt. Also ist
\begin{eqnarray*}
	\gamma_k(i) := \mathbb{E}\left(\sum_{n=1}^{T_{k,k}} \mathds{1}_{\{X_n=i\}}\right).
\end{eqnarray*}
Dann gilt:
	\begin{enumerate}[label=(\roman{*})]
		\item $\gamma_k$ ist ein invariantes Maß
		\item Für alle $i \in I$ gilt $0 < \gamma_k(i) < \infty$
		\item $\gamma_k$ ist das einzige invariante Maß mit Wert $1$ in $k$.
	\end{enumerate}
\end{satz}
	
\textbf{Beweis:}\\
\begin{itemize}
\item $(i)$:
Durch Anwendung des Satzes der monotonen Konvergenz\footnote{siehe Anhang \ref{sa:monotoneKonv}} und Ausnutzung der Markov-Eigenschaft, können wir zeigen, dass $\gamma_k$ ein invariantes Maß ist. Dazu sei $i\in I$ ein beliebiger Zustant, dann gilt
\begin{eqnarray*}
	\gamma_k(i) &=& \mathbb{E}\left(\sum_{n=1}^{T_{k,k}} \mathds{1}_{\{X_n=i, n\leq T_{k,k}\}}\right)\\
							&=& \sum_{n\in \mathbb{N}} \mathbb{P}(X_n=i, n\leq T_{k,k}) \\
							&=& \sum_{n\in \mathbb{N}} \sum_{j\in I} \mathbb{P}(X_n=i, X_{n-1} = j, n\leq T_{k,k}) \\
							&=& \sum_{n\in \mathbb{N}} \sum_{j\in I} \mathbb{P}(X_{n-1}=j, n\leq T_{k,k}) \mathbb{P}(X_n=i | X_{n-1} = j) \\
							&=& \sum_{n\in \mathbb{N}} \sum_{j\in I} \mathbb{P}(X_{n-1}=j, n-1\leq T_{k,k}-1) p_{j,i} \\
							&=& \sum_{j\in I} p_{j,i} \sum_{n\in \mathbb{N}_0}  \mathbb{P}(X_n=j, n\leq T_{k,k}-1)  \\
							&=& \sum_{j\in I} p_{j,i} \mathbb{E}\left(\sum_{n=0}^{T_{k,k}-1} \mathds{1}_{\{X_n=j\}}\right)  \\
							&=& \sum_{j\in I} p_{j,i} \mathbb{E}\left(\sum_{n=1}^{T_{k,k}} \mathds{1}_{\{X_n=j\}}\right)  \\
							&=& \sum_{j\in I} \gamma_k(j) p_{j,i}.   
\end{eqnarray*}

\item $(ii)$:
Wir haben gezeigt, dass $\gamma_k$ ein invariantes Maß ist. Also folgt insbesondere für alle $n\in \mathbb{N}$ und $j \in I$
\begin{eqnarray*}
	1=\gamma_k(k) \geq \gamma_k(j)p_{j,k}^{(n)}. 
\end{eqnarray*}
Aufgrund der Irreduzibilität existiert für jedes j ein n mit $p_{j,k}^{(n)} >0$ und deshalb ist $\gamma_k(j)<\infty$ für jedes $j$. Außerdem ist 
\begin{eqnarray*}
	\gamma_k(j) \geq \gamma_k(k)p_{k,j}^{(n)} = p_{k,j}^{(n)} >0
\end{eqnarray*}
für ein geeignetes n.

\item $(iii)$:
Sei $\lambda$ ein invariantes Maß mit $\lambda(k) =1$. Aufgrund der Invarianz gilt für jedes $j \in I$:
\begin{eqnarray*}
	\lambda(j) &=& \sum_{i\in I\backslash\{k\}} \lambda(i) p_{i,j} + p_{k,j}\\
						 &=& \sum_{i\in I\backslash\{k\}} \big( \sum_{i_1\in I\backslash\{k\}} \lambda(i_1) p_{i_1,i} + p_{k,i} \big) p_{i,j} + p_{k,j} \\
						 &=& \sum_{i, i_1 \in I\backslash\{k\}} \lambda(i_1) p_{i_1,i} + \sum_{i\in I\backslash\{k\}} p_{k,i} p_{i,j} + p_{k,j} \\
						 &=& \sum_{i, i_1 \in I\backslash\{k\}} \lambda(i_1) p_{i_1,i} + \mathbb{P}(T_{k,k} \geq 2, X_2 =j) +  \mathbb{P}(T_{k,k} \geq 1, X_1 =j) \\
						 &=& ... \\
						 &=& \sum_{i, i_1,..., i_n \in I\backslash\{k\}}	\lambda(i_n) \big( \prod_{r=1}^n p_{i_r,i_{r-1}}\big) p_{i,j} + \sum_{r=1}^{n+1} \mathbb{P}(T_{k,k} \geq r, X_r =j)\\
						&\geq& \sum_{r=1}^{n+1} \mathbb{P}(T_{k,k} \geq r, X_r =j)\\
						&=& \mathbb{E} \big( \sum_{r=1}^{min\{T_{k,k}, n+1\}} \mathds{1}_{\{X_r=j\}}\big)\\
						&\xrightarrow{n\rightarrow \infty}& \gamma_k(j)
\end{eqnarray*}
Das heißt $\lambda(j) \geq \gamma_k(j)$ für alle $j\in I$. Deshalb ist $\lambda - \gamma_k$ auch ein invariantes Maß mit einer Nullstelle in k. Da die Kette aber irreduzibel ist, muss $\lambda - \gamma_k = 0$ sein und dies beweist die Eindeutigkeit von  $\gamma_k$.
\end{itemize}
\qed	

\begin{satz} \label{sa:gleichgewicht} Sei $\{X_n, n \in \mathbb{N}\}$ eine irreduzible Markov-Kette mit Übergangsmatrix $P$, dann sind folgende Aussagen äquivalent: 
	\begin{enumerate}[label=(\roman{*})]
		\item Es existiert eine Gleichgewichtsverteilung.
		\item Es existiert ein positiv rekurrenter Zustand $i \in I$.
		\item Alle Zustände in $I$ sind positiv rekurrent.
	\end{enumerate}
	Außerdem gilt, falls eine dieser Bedingungen erfüllt ist, dass die Gleichgewichtsverteilung $\pi$ eindeutig bestimmt ist und es ist $\pi(i) = \frac{1}{\mu _i}$.
\end{satz}

\textbf{Beweis:}\\
\begin{itemize}
\item $(iii) \Rightarrow (ii)$: Diese Richtung ist trivial.

\item $(ii) \Rightarrow (i)$:
Wir zeigen, dass das im letzten Satz definierte invariante Maß $\gamma$ auch zu einer Verteilung normiert werden kann und damit dann eine Gleichgewichtsverteilung ist. Dazu sei im folgenden $k \in I$ der positiv rekurrente Zustand, damit gilt
\begin{eqnarray*}
	\sum_{j\in I} \gamma_k(j) &=& \sum_{j\in I}\mathbb{E}\big(\sum_{n=1}^{T_{k,k}} \mathds{1}_{\{X_n=j\}}\big)\\
							&=& \mathbb{E}\big(\sum_{n=1}^{T_{k,k}} \underbrace{\sum_{j\in I}\mathds{1}_{\{X_n=j\}}}_{1}\big) \\
							&=& \mathbb{E}(T_{k,k}) = \mu _k <\infty.
\end{eqnarray*}
\item $(i) \Rightarrow (iii)$:
Sei $\pi$ eine Gleichgewichtsverteilung und sei $k\in I$, dann ist $\gamma = \frac{\pi}{\pi(k)}$ ein invariantes Maß mit $\gamma(k) =1$. Wir haben im vorherigen Satz gezeigt, dass es in diesem Fall nur ein invariantes Maß mit Wert 1 in k gibt, das heißt $\gamma= \gamma_k$. Damit folgt
\begin{eqnarray*}
	\mu _k = \sum_{j\in I}\gamma _k(j) = \sum_{j\in I}\gamma(j) = \frac{1}{\pi(k)}\sum_{j\in I} \pi(j) = \frac{1}{\pi(k)} < \infty
\end{eqnarray*}
Da dies für alle k gilt, sind alle Zustände positiv rekurrent. Der letzte Teil des Satzes folgt direkt aus dem diesem Beweisschritt.
\end{itemize}
\qed

Leider ist es gerade bei komplexeren Markov-Ketten nicht immer möglich, die stationäre Verteilung analytisch zu bestimmen. Unter bestimmten Voraussetzungen kann sie aber zumindest angenähert werden.

\begin{satz} Sei $\{X_n, n \in \mathbb{N}\}$ eine irreduzible Markov-Kette mit aperiodischen und positiv rekurrenten Zuständen und Gleichgewichtsverteilung $\pi$. Dann gilt für alle $i, j \in I$ 
\begin{eqnarray*}
	\lim_{n\rightarrow \infty} p_{i,j}^{(n)} = \pi(j). 
\end{eqnarray*}
Das heißt durch wiederholtes Potenzieren der Matrix der Übergangswahrscheinlichkeiten, konvergiert jede Zeile gegen die Gleichgewichtsverteilung.
\end{satz}

Auf den Beweis dieser Aussage wird an dieser Stelle verzichtet. Eine vollständige Ausführung des Satzes findet sich in \cite[Kapitel 4 -Theorem 4.1.4]{kemenySnell}. 
